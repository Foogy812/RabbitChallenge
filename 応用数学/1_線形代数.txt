■機械学習において線形代数を学ぶ意味
　機械学習において最適化するパラメータは、通常はベクトルもしくはベクトルの集合である行列である。
　そこでベクトル・行列の演算である線形代数の理解が必須となる。

■ベクトルの内積の意味
　ベクトルの内積とは、一方のベクトルを他方のベクトル空間へ変換する行為と考えられる。
　例えばベクトルaとbの内積は
   ・aのbへの射影のbのノルム倍
   　または
   ・bのaへの射影のaのノルム倍
  と考えることができ、ベクトルが他方のベクトル数直線上のスカラ値へと変換される。
 
■正方行列を左からベクトルにかけることの意味
　正方行列Aをベクトルxに左からかけることで、別のベクトルyに変換され、次の式が成り立つ。
  Ax = y = ΣλnZn （λn：Aのn番目の固有値、Zn：Aのn番目の固有ベクトルに対するxの射影）

　このように正方行列の固有値・固有ベクトルはその行列による変換のベースとなる特別な値である。

■固有値分解
　正方行列Aは特異値・特異ベクトルにより下記の通り表すことができる。
　A = VΛV-1　（V：固有ベクトル（列ベクトル）を各列に並べたもの、Λ：固有値を対角線状に並べた対角行列
　この固有値分解を行うことで、行列の累乗の演算が簡単になる。
 
■特異値・特異ベクトル
　固有値分解は行列の累乗演算を簡単にする利点がある一方、正方行列にしか適用できないという課題がある。
　その課題を解決する方法が、特異値分解である。
　行列Mは次のように特異値分解することができる。
　M　= USV　
 　U：左特異ベクトル（列ベクトル）を各列にならべた行列
 　S:Mと同じshapeの行列で特異値を対角成分に並べ、他成分はゼロ
 　V：左特異ベクトル（列ベクトル）を各列にならべた行列
　
　特異値・特異ベクトルは、MとMtの積、およびMtとMの積を固有値分解することで導くことができる。
　機械学習においては、データ行列を特異値分解し特異値が小さい成分を削除することで、データの圧縮を行うことができる。
